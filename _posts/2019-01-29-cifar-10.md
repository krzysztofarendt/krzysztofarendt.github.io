---
layout: post
title: "CIFAR-10 images: classification using MLP vs. CNN"
published: false
tags: Python, computer vision, Keras, Tensorflow
---

# Data, Python packages, and online resources

* Data: [CIFAR-10](https://www.cs.utoronto.ca/~kriz/cifar.html) image set
* Python packages: [Keras](https://keras.io/) with [Tensorflow](https://www.tensorflow.org/) backend, matplotlib, numpy, pandas
* Filter visualization based on: [How Convolutional Neural Networks See the World?](https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html) by Francois Chollet

The code used to generate these figures can be found [here](/gfx/cifar-10/keras_test2.html).

# Network architectures

Multi-layer perceptron (MLP):
- 2 hidden layers

```
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 3072)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               393344    
_________________________________________________________________
dropout_1 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                4128      
_________________________________________________________________
dense_3 (Dense)              (None, 10)                330       
=================================================================
Total params: 397,802
Trainable params: 397,802
Non-trainable params: 0
_________________________________________________________________
```

Convolutional Neural Network (CNN):

```
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 7200)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 10)                72010     
_________________________________________________________________
activation_1 (Activation)    (None, 10)                0         
=================================================================
Total params: 72,906
Trainable params: 72,906
Non-trainable params: 0
_________________________________________________________________
```

# Figures

![Training and validation](/gfx/cifar-10/training_vs_validation.png)
**Fig. 1:** Training (continuous line) and validation (dash line) history for MLP (blue) and CNN (red).

![Exemplary images](/gfx/cifar-10/exemplary_images.png)
**Fig. 2:** Exemplary validation images and labels predicted by CNN.

![Prediction difficulties per class](/gfx/cifar-10/incorrect_share.png)
**Fig. 3:** Prediction difficulties per class.

![Filter visualization](/gfx/cifar-10/filters.png)
**Fig. 4:** Images maximizing the filter output a.k.a. "filter visualization".

![Ideal images](/gfx/cifar-10/ideal_images.png)
**Fig. 5:** Images maximizing the specific class (e.g. how an ideal cat looks according to this CNN?)

# Conclusions

- Overall validation accuracy: MLP = 44%, CNN = 62%. Not great, but that accuracy was not the main aim here.
- Many filters look at similar features (e.g. 3 and 15, 10 and 11, 25 and 28) but at different rotation, because CNNs are translation-invariant but not rotation-invariant.
- The presented CNN deals best with automobiles and ships and not so well with animals. I tried training the network few times, each time getting slightly different share of incorrect predictions per class, but with a similar trend. Probably a more advanced architecture of the network is needed or some sort of regularization to make it more accurate for animal classes. This one was limited to just one convolutional layer with 32 filters so that I could train it in several minutes on my laptop.
- The CNN seems to be slightly overfitted (Fig. 1), as we can see that the training accuracy diverges from the validation accuracy. However, the validation accuracy stays almost constant rather than decreasing over time. That might point again to the over-simplistic architecture of the network.
