---
layout: post
title: "MNIST: linear SVM vs. deep feedforward NN"
published: true
tags: python, matplotlib, scikit-learn, keras, tensorflow
---

An example of image classification based on the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) data set. The original code used to produce the results is [here](https://github.com/krzysztofarendt/kaggle-mnist/blob/master/handwriting.ipynb).

# Data set

The MNIST data set contains 60000 labeled gray-scale images of hand-drawn digits, from 0 through 9. The data set used in this post is a subset of the original MNIST, containing 42000 samples. Some exemplary digits:

![Data set](/gfx/mnist/data_set.png)

In this analysis the data is split into two sets, one for training (80%) and one for validation (20%). The methods are compared in terms of the classification *accuracy*, defined as the fraction of properly classified digits. 

# Linear SVM classifier: training

Before the model is tested on the validation data set, let's check out how the model's accuracy depend on the sample size. The following curves were obtained using a 5-fold cross-validation, based on the training data only:

![SVM cross-validatin](/gfx/mnist/svm_5-fold-cv.png)

As shown, the model performance doesn't improve significantly above 10000 training examples. We can conclude that we have enough data in the training set for the linear SVM. The average accuracy of the linear SVM is not very impressive, but it's fast and easy to train. Finally, let's train the model using all the training examples. I used the default hyperparameters from [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html):

```python
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0)
```

# Linear SVM classifier: validation

The validation accuracy is equal to **87.65%**, which is similar to the result depicted in the learning curve figure. Let's take a look at exemplary predictions together with the decision boundary:

![Example 1](/gfx/mnist/svm_ex1.png)
![Example 2](/gfx/mnist/svm_ex2.png)
![Example 3](/gfx/mnist/svm_ex3.png)
![Example 4](/gfx/mnist/svm_ex4.png)
![Example 5](/gfx/mnist/svm_ex5.png)

As shown, the model properly classifies most of the digits, however often is relatively *unsure*. E.g. it often confuses 5's and 8's, and 6's are easily confused with 0's, 2's, or 8's. 

# Deep NN: training

Let's test a (not very) deep ANN with 4 hidden layers, with 128, 64, 32 and 16 neurons each. All hidden neurons are defined with the rectifier activation function:  f(x)=max(0,x). The output layer uses the softmax function and contains 10 neurons, i.e. 1 neuron per possible outcome (0, 1, 2, ..., 9). In this example I used [Keras](https://keras.io/)+[TensorFlow](https://www.tensorflow.org/):

```python
model = Sequential()
model.add(Dense(128, activation='relu', input_dim=784))
model.add(Dropout(0.15))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.15))
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.15))
model.add(Dense(16, activation='relu'))
model.add(Dense(10, activation='softmax'))
```

Usually it's a good idea to normalize the data before training a model. In this case, however, the result shouldn't change much, because all pixels already contain values between 0 and 255 (the same range in all samples), and the rectifier function can yield any positive value. Anyway, 0-1 range looks nicer, so let's scale down the data.

E.g. after normalization, the digit '4' looks as follows (null-margins cropped):

![Normalized digit](/gfx/mnist/normalized_4.png)

```python
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(x_train, y_train, epochs=30, batch_size=50, validation_split=0.05)
```

![ANN traning](/gfx/mnist/ann_training.png)

# Deep NN: validation

The neural network achieved an excellent accuracy of **99.04%**. Below you can see exemplary predictions:

![ANN validation](/gfx/mnist/ann_validation.png)

# Comparison: SVM vs NN

It's clear that linear models are not suitable for image classification. In this example the linear SVM and the neural network achieved the accuracy of 87.65% and 99.04%, respectively:

![Comparison](/gfx/mnist/comparison.png)